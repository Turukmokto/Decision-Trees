# Decision-Trees

Tree:
1. Build a decision tree on the given dataset.
2. Visualize the resulting tree.
3. Plot classification quality versus decision tree depth on the test and training parts of the dataset.

Random forest:
1. Plot the classification quality versus the number of trees on the test and training parts of the dataset.
2. Visualize how the entire space is classified by the algorithm for a different number of trees. There should be several pictures. It is not necessary to 3. build pictures for each step. You can select several “interesting” iteration numbers, for example: 1, 2, 3, 5, 8, 13, 21, 34…

Boosting:
1. Repeat the previous two points, but use some kind of boosting algorithm instead of a random forest.
